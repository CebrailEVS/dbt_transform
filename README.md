# ğŸ§± EVS Data Transformation (dbt)

Transformations de donnÃ©es dbt pour **EVS Professionnelle France** dans une stack ELT moderne orchestrÃ©e via Airflow.

## ğŸ“‹ Vue d'ensemble

### Stack Technique

| Composant       | RÃ´le                                    |
|-----------------|----------------------------------------|
| **Meltano**     | Extraction et chargement vers BigQuery |
| **BigQuery**    | Data Lake + Data Warehouse             |
| **dbt**         | Transformation et modÃ©lisation         |
| **Airflow**     | Orchestration production               |
| **GitHub Actions** | CI/CD automatisÃ©e                   |
| **Power BI**    | Visualisation et reporting             |

### Architecture des ModÃ¨les

```
models/
â”œâ”€â”€ staging/          # ğŸ”„ Nettoyage et standardisation (zone partagÃ©e)
â”‚   â”œâ”€â”€ oracle_neshu/
â”‚   â””â”€â”€ yuman/
â”œâ”€â”€ intermediate/     # ğŸ‘¤ Logique mÃ©tier complexe (Data Engineer)
â”‚   â””â”€â”€ oracle_neshu/
â””â”€â”€ marts/           # ğŸ“Š ModÃ¨les finaux orientÃ©s business
    â”œâ”€â”€ oracle_neshu/ # ğŸ‘¤ Business logic (Data Engineer)
    â””â”€â”€ yuman/        # ğŸ“Š Analytics (Data Analyst)
```

## ğŸš€ Installation & Configuration

### PrÃ©requis

- Python 3.10.13
- AccÃ¨s BigQuery avec permissions appropriÃ©es
- ClÃ© de service GCP configurÃ©e

### Installation

```bash
# 1. Cloner le repository
git clone https://github.com/CebrailEVS/dbt_transform.git
cd dbt_transform

# 2. Environnement virtuel (recommandÃ©)
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou venv\Scripts\activate  # Windows

# 3. Installer dbt
pip install dbt-bigquery

# 4. Configurer les variables d'environnement
cp .env.example .env  # Ajuster les valeurs selon votre environnement

# 5. Charger les variables (OBLIGATOIRE avant chaque session dbt)
set -a && source .env && set +a

# 6. Tester la configuration
dbt debug
```

### Configuration des Variables

Fichier `.env` :
```bash
# Environment cible
DBT_TARGET=dev  # dev (Data Engineer) | dev_analyst (Data Analyst) | prod

# Configuration BigQuery
DBT_BIGQUERY_PROJECT=evs-datastack-prod
DBT_BIGQUERY_KEYFILE=/chemin/vers/votre/cle.json

# Datasets
DBT_BIGQUERY_DATASET_DEV=dev
DBT_BIGQUERY_DATASET_PROD=prod
```

## ğŸŒ Gestion des Environnements

### RÃ©partition des Environnements

| Environnement | Utilisateur    | Dataset BigQuery | Usage                    |
|---------------|----------------|------------------|--------------------------|
| `dev`         | Data Engineer  | `dev`           | DÃ©veloppement principal  |
| `dev_analyst` | Data Analyst   | `dev_analyst`   | DÃ©veloppement analytique |
| `prod`        | Airflow        | `prod`          | Production automatisÃ©e   |

### Zones de ResponsabilitÃ©

- **ğŸ”„ Zone PartagÃ©e** (`staging/`) : Coordination requise entre Ã©quipes
- **ğŸ‘¤ Zone Data Engineer** (`intermediate/`, `marts/oracle_neshu/`) : Business logic
- **ğŸ“Š Zone Data Analyst** (`marts/yuman/`) : Analytics et reporting

## ğŸ’» Utilisation Quotidienne

### Commandes Essentielles

```bash
# âš ï¸ TOUJOURS commencer par charger les variables
set -a && source .env && set +a

# Installation des dÃ©pendances
dbt deps

# ExÃ©cution des modÃ¨les
dbt run                              # Tous les modÃ¨les
dbt run --select stg_yuman__clients  # ModÃ¨le spÃ©cifique
dbt run --select staging.yuman      # Tous les modÃ¨les d'une source

# Tests de qualitÃ©
dbt test                             # Tous les tests
dbt test --select stg_yuman__clients # Tests d'un modÃ¨le

# Documentation
dbt docs generate && dbt docs serve
```

### Alias Utile

Ajoutez Ã  votre `.bashrc` ou `.zshrc` :
```bash
alias dbt-env="set -a && source .env && set +a"
```

## ğŸ¤ Workflow Collaboratif

### DÃ©marrage de JournÃ©e

```bash
# 1. RÃ©cupÃ©rer les derniÃ¨res modifications
git checkout master && git pull origin master

# 2. Travailler sur votre branche
git checkout feature/votre-branche
# ou crÃ©er une nouvelle branche
git checkout -b feature/nouvelle-fonctionnalite

# 3. Si votre branche est ancienne, synchroniser
git rebase master
```

### Cycle de DÃ©veloppement

```bash
# 1. Charger l'environnement
set -a && source .env && set +a

# 2. DÃ©velopper et tester
dbt run --target votre_environnement
dbt test --target votre_environnement

# 3. Commits rÃ©guliers
git add .
git commit -m "feat: add dim_oracle_neshu__product model"

# 4. Push quand la fonctionnalitÃ© est prÃªte
git push origin feature/votre-branche
```

### Processus de Pull Request

1. **Synchronisation finale avec master**
   ```bash
   git checkout master && git pull origin master
   git checkout feature/votre-branche && git rebase master
   ```

2. **Tests complets**
   ```bash
   dbt run --target votre_environnement
   dbt test --target votre_environnement
   ```

3. **Push et crÃ©ation de la PR**
   ```bash
   git push origin feature/votre-branche --force-with-lease
   ```

4. **Review** : Le Data Engineer review les PR du Data Analyst et vice versa

### Conventions de Nommage

```bash
# Branches
feature/modelisation-oracle_neshu
feature/analytics-yuman-workorders
feature/fix-telemetry-join

# Commits
feat: add new dimension model
fix: correct join logic in staging
docs: update model documentation
```

## ğŸ§ª Tests et QualitÃ©

Les tests dbt incluent :
- Tests d'unicitÃ© et de non-nullitÃ©
- Tests de rÃ©fÃ©rence entre modÃ¨les
- Tests personnalisÃ©s mÃ©tier

Configuration dans les fichiers `*_models.yml` :
```yaml
models:
  - name: stg_yuman__clients
    tests:
      - unique:
          column_name: client_id
      - not_null:
          column_name: client_id
```

## ğŸš¦ RÃ¨gles de Collaboration

### âœ… Bonnes Pratiques

- Toujours partir de `master` Ã  jour
- Tester localement avant de push
- Communiquer avant de modifier les zones partagÃ©es
- Utiliser des messages de commit descriptifs
- CrÃ©er des PR pour toute modification

### âŒ Ã€ Ã‰viter

- Push direct sur `master`
- Modifier `staging/` sans coordination
- Merger ses propres PR sans review
- Ignorer les tests qui Ã©chouent

### Communication Requise

PrÃ©venez-vous mutuellement avant de modifier :
- `dbt_project.yml`
- Fichiers dans `staging/` (sources communes)
- `*_sources.yml` (dÃ©finitions des sources)
- Macros partagÃ©es

## ğŸ”„ CI/CD Automatique

Le workflow GitHub Actions se dÃ©clenche automatiquement :

- **Push vers `master`** â†’ DÃ©ploiement automatique en production
- **Push vers `feature/**`** â†’ Tests de validation en dev
- **Pull Request** â†’ Tests complets avant merge

## ğŸ“– Documentation

La documentation est gÃ©nÃ©rÃ©e automatiquement et inclut :
- Lineage des modÃ¨les
- Description des colonnes
- Tests appliquÃ©s
- MÃ©triques de qualitÃ©

AccÃ¨s via `dbt docs serve` aprÃ¨s `dbt docs generate`.

## ğŸ†˜ DÃ©pannage

### ProblÃ¨mes Courants

```bash
# Variables d'environnement non chargÃ©es
dbt debug  # VÃ©rifier la configuration

# Conflits Git complexes
git rebase --abort  # Annuler et demander de l'aide

# Tests qui Ã©chouent
dbt test --select fail  # Voir uniquement les tests en Ã©chec
```

### Support

En cas de problÃ¨me :
1. Utiliser `git status` pour comprendre l'Ã©tat actuel
2. Faire `git rebase --abort` si nÃ©cessaire
3. Demander de l'aide avant de forcer des opÃ©rations

## ğŸ”— Ressources

- [Documentation dbt](https://docs.getdbt.com/)
- [dbt BigQuery Adapter](https://docs.getdbt.com/docs/core/connect-data-platform/bigquery-setup)
- [Repository GitHub](https://github.com/CebrailEVS/dbt_transform)

---

**DÃ©veloppÃ© avec â¤ï¸ par l'Ã©quipe Data EVS**